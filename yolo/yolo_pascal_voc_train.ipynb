{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trIYxN0IYJu6",
        "outputId": "9eb6306d-114e-4c10-b4ee-4cceee3177e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets.voc import VOCDetection\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam"
      ],
      "metadata": {
        "id": "tWwVKq_5Y3UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "architecture_config = [\n",
        "    (7, 64, 2, 3),\n",
        "    \"M\",\n",
        "    (3, 192, 1, 1),\n",
        "    \"M\",\n",
        "    (1, 128, 1, 0),\n",
        "    (3, 256, 1, 1),\n",
        "    (1, 256, 1, 0),\n",
        "    (3, 512, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],\n",
        "    (1, 512, 1, 0),\n",
        "    (3, 1024, 1, 1),\n",
        "    \"M\",\n",
        "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 2, 1),\n",
        "    (3, 1024, 1, 1),\n",
        "    (3, 1024, 1, 1),\n",
        "]\n",
        "\n",
        "\n",
        "class block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(block, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, bias=False, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(num_features=out_channels)\n",
        "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.1)\n",
        "    def forward(self, x):\n",
        "        return self.leaky_relu(self.batchnorm(self.conv(x)))\n",
        "\n",
        "\n",
        "class Yolo(nn.Module):\n",
        "    def __init__(self, in_channels=3, grid_size=7, num_boxes=2, num_classes=20):\n",
        "        super(Yolo, self).__init__()\n",
        "        self._in_channels = in_channels\n",
        "        self._grid_size = grid_size\n",
        "        self._num_boxes = num_boxes\n",
        "        self._num_classes = num_classes\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((448, 448))\n",
        "        self.architecture = architecture_config\n",
        "        self.conv_part = self._create_conv_layers(\n",
        "            architecture=self.architecture,\n",
        "            in_channels=self._in_channels\n",
        "            )\n",
        "        self.fcs = self._create_fc_layers(\n",
        "            grid_size=self._grid_size,\n",
        "            num_boxes=self._num_boxes,\n",
        "            num_classes=self._num_classes\n",
        "            )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        S = self._grid_size\n",
        "        B = self._num_boxes\n",
        "        C = self._num_classes \n",
        "        x = self.avgpool(x)\n",
        "        x = self.conv_part(x)\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        x = x.view(-1, S, S, C + B * 5)\n",
        "        return x\n",
        "\n",
        "    @staticmethod    \n",
        "    def _create_fc_layers(grid_size, num_boxes, num_classes):\n",
        "        S, B, C = grid_size, num_boxes, num_classes\n",
        "        return nn.Sequential(nn.Linear(1024 * S * S, 4096), \n",
        "                             nn.Dropout(p=0.5),\n",
        "                             nn.LeakyReLU(negative_slope=0.1),\n",
        "                             nn.Linear(4096, S * S * (C + B * 5)),\n",
        "                             nn.ReLU())\n",
        "\n",
        "    @staticmethod           \n",
        "    def _create_conv_layers(architecture, in_channels):\n",
        "        layers = list()\n",
        "        for x in architecture:\n",
        "            if isinstance(x, tuple):\n",
        "                kernel_size = x[0]\n",
        "                out_channels = x[1]\n",
        "                stride = x[2]\n",
        "                padding = x[3]\n",
        "                layers.append(block(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size,\n",
        "                                    stride=stride, padding=padding))\n",
        "                in_channels = x[1]\n",
        "                \n",
        "            elif isinstance(x, str):\n",
        "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "                \n",
        "            elif isinstance(x, list):\n",
        "                layer1 = x[0]\n",
        "                layer2 = x[1]\n",
        "                times = x[2]\n",
        "                \n",
        "                for _ in range(times):\n",
        "                    layers.append(block(in_channels=in_channels,\n",
        "                                        out_channels=layer1[1],\n",
        "                                        kernel_size=layer1[0],\n",
        "                                        stride=layer1[2],\n",
        "                                        padding=layer1[3]))\n",
        "                    layers.append(block(in_channels=layer1[1],\n",
        "                                        out_channels=layer2[1],\n",
        "                                        kernel_size=layer2[0],\n",
        "                                        stride=layer2[2],\n",
        "                                        padding=layer2[3]))\n",
        "                    in_channels = layer2[1]\n",
        "          \n",
        "        return nn.Sequential(*layers)\n",
        "        "
      ],
      "metadata": {
        "id": "7QatB66NslOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def _return_corner_coordinates(boxes, box_format):\n",
        "    if box_format == \"midpoint\":\n",
        "        x = boxes[..., 0:1]\n",
        "        y = boxes[..., 1:2]\n",
        "        boxes_width = boxes[..., 2:3]\n",
        "        boxes_height = boxes[..., 3:4]\n",
        "        box_x1 = x - boxes_width / 2\n",
        "        box_y1 = y - boxes_height / 2\n",
        "        box_x2 = x + boxes_width / 2\n",
        "        box_y2 = y + boxes_height / 2\n",
        "    elif box_format == \"corners\":\n",
        "        box_x1 = boxes[..., 0:1]\n",
        "        box_y1 = boxes[..., 1:2]\n",
        "        box_x2 = boxes[..., 2:3]\n",
        "        box_y2 = boxes[..., 3:4]\n",
        "    return box_x1, box_y1, box_x2, box_y2\n",
        "\n",
        "\n",
        "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
        "    box1_x1, box1_y1, box1_x2, box1_y2 = _return_corner_coordinates(boxes_preds, box_format=box_format)\n",
        "    box2_x1, box2_y1, box2_x2, box2_y2 = _return_corner_coordinates(boxes_labels, box_format=box_format)\n",
        "    # Intersection rectangle corner coordinates\n",
        "    x1 = torch.max(box1_x1, box2_x1)\n",
        "    y1 = torch.max(box1_y1, box2_y1)\n",
        "    x2 = torch.min(box1_x2, box2_x2)\n",
        "    y2 = torch.min(box1_y2, box2_y2)\n",
        "\n",
        "    dx = x2 - x1\n",
        "    dy = y2 - y1\n",
        "    intersection_area = dx.clamp(0) * dy.clamp(0)  # in case they don't intersect\n",
        "    box1_area = torch.abs((box1_x1 - box1_x2) * (box1_y1 - box1_y2))\n",
        "    box2_area = torch.abs((box2_x1 - box2_x2) * (box2_y1 - box2_y2))\n",
        "    union_area = box1_area + box2_area - intersection_area\n",
        "    return intersection_area / union_area\n",
        "\n",
        "def get_object_loss(target, bestbox, predictions, exists_box, s=-9):\n",
        "    pred_box = bestbox * predictions[..., 25+s:26+s] + (1 - bestbox) * predictions[..., 20+s:21+s]\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    object_loss = mse(exists_box * pred_box, \n",
        "            exists_box * target[..., 20+s:21+s])\n",
        "    return object_loss\n",
        "\n",
        "def get_no_object_loss(exists_box, predictions, target, s=-9):\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    return (\n",
        "        mse((1. - exists_box) * predictions[..., 20+s:21+s], (1. - exists_box) * target[..., 20+s:21+s]) +\n",
        "        mse((1. - exists_box) * predictions[..., 25+s:26+s], (1. - exists_box) * target[..., 20+s:21+s])\n",
        "    )\n",
        "\n",
        "def get_class_loss(exists_box, predictions, target, s=-9):\n",
        "    mse = nn.MSELoss(reduction=\"sum\")\n",
        "    return mse(exists_box * predictions[..., :20+s], exists_box * target[..., :20+s])\n",
        "\n",
        "\n",
        "\n",
        "class YoloLoss(nn.Module):\n",
        "    def __init__(self, grid_size=7, num_boxes=2, num_classes=20):\n",
        "        super(YoloLoss, self).__init__()\n",
        "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
        "        self.S = grid_size\n",
        "        self.B = num_boxes\n",
        "        self.C = num_classes\n",
        "        self.lambda_coord = 5\n",
        "        self.lambda_noobj = 0.5\n",
        "        \n",
        "    def forward(self, predictions, target):  # (N, S, S, C + B * 5)\n",
        "        \n",
        "        # Determine \"responsible\" bounding box predictor (based on the highest IoU)\n",
        "        s = self.C - 20\n",
        "        iou_b1 = intersection_over_union(predictions[..., 21+s:25+s], target[..., 21+s:25+s])\n",
        "        iou_b2 = intersection_over_union(predictions[..., 26+s:30+s], target[..., 21+s:25+s])\n",
        "        ious = torch.cat([iou_b1.unsqueeze(dim=0), iou_b2.unsqueeze(dim=0)], dim=0)\n",
        "        iou_maxes, bestbox = torch.max(ious, dim=0)\n",
        "        exists_box = target[..., 20+s].unsqueeze(3)  # I_obj (zero or one)\n",
        "        \n",
        "        # Box coordinates loss\n",
        "        \n",
        "        box_predictions = exists_box * (bestbox * predictions[..., 26+s:30+s] + (1 - bestbox) * predictions[..., 21+s:25+s])\n",
        "        box_targets = exists_box * target[..., 21+s:25+s]\n",
        "        # box_predictions = box_predictions1.clone()\n",
        "        # box_targets = box_targets1.clone()\n",
        "        \n",
        "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(torch.abs(box_predictions[..., 2:4] + 1e-6))\n",
        "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
        "        \n",
        "        # (N, S, S, 4) -> (N*S*S, 4)\n",
        "        box_loss = self.mse(box_predictions, box_targets)\n",
        "        \n",
        "        object_loss = get_object_loss(\n",
        "            target=target,\n",
        "            bestbox=bestbox,\n",
        "            predictions=predictions,\n",
        "            exists_box=exists_box,\n",
        "            s=-9,\n",
        "        )\n",
        "        no_object_loss = get_no_object_loss(\n",
        "            exists_box=exists_box,\n",
        "            predictions=predictions,\n",
        "            target=target,\n",
        "            s=-9,\n",
        "        )\n",
        "        class_loss = get_class_loss(\n",
        "            exists_box=exists_box,\n",
        "            predictions=predictions,\n",
        "            target=target,\n",
        "            s=-9,\n",
        "        )\n",
        "\n",
        "        loss = (\n",
        "            self.lambda_coord * box_loss +\n",
        "            object_loss +\n",
        "            self.lambda_noobj * no_object_loss + \n",
        "            class_loss\n",
        "        )\n",
        "        return loss"
      ],
      "metadata": {
        "id": "PhfLvPcZslAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((333, 500)),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "VkQZ_drMZHxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "S = 7\n",
        "B = 2\n",
        "C = 20\n",
        "NUM_CHANNELS = 3"
      ],
      "metadata": {
        "id": "5ElhPU025jTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_names2classes(class_name):\n",
        "    classes = [\"person\", \"bird\", \"cat\", \"cow\", \"dog\", \"horse\", \"sheep\", \"aeroplane\", \"bicycle\", \"boat\", \"bus\", \"car\", \"motorbike\", \"train\", \"bottle\", \"chair\", \"diningtable\", \"pottedplant\", \"sofa\", \"tvmonitor\"]\n",
        "    for i in range(len(classes)):\n",
        "        if class_name == classes[i]:\n",
        "          return i"
      ],
      "metadata": {
        "id": "hp-OyvTp6Dzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = tuple(zip(*batch))\n",
        "    x_b, y_b = data\n",
        "    y_batch = []\n",
        "    for i in range(len(y_b)):\n",
        "        y = y_b[i]\n",
        "        y_label = []\n",
        "        x_size, y_size = y['annotation']['size']['width'], y['annotation']['size']['height']\n",
        "        for item in y['annotation']['object']:\n",
        "            class_name = item['name']\n",
        "            bndbox = item['bndbox']\n",
        "            class_label = int(class_names2classes(class_name))\n",
        "            xmin, xmax, ymin, ymax = int(bndbox[\"xmin\"]) / int(x_size), int(bndbox[\"xmax\"]) / int(x_size), int(bndbox[\"ymin\"]) / int(y_size), int(bndbox[\"ymax\"]) / int(y_size)\n",
        "            y_label.append([class_label, (xmax+xmin) / 2, (ymax+ymin) / 2, xmax-xmin, ymax-ymin])\n",
        "        y_batch.append(y_label)\n",
        "    \n",
        "    label_matrices = []\n",
        "    for y_ in y_batch:\n",
        "        label_matrix = torch.zeros((S, S, C + 5 * B))\n",
        "        for box in y_:\n",
        "            class_label, x, y, width, height = box\n",
        "            i, j = int(S * y), int(S * x)\n",
        "            x_cell, y_cell = S * x - j, S * y - i\n",
        "            width_cell, height_cell = (\n",
        "                width * S,\n",
        "                height * S,\n",
        "            )\n",
        "\n",
        "            if label_matrix[i, j, 20] == 0:\n",
        "                label_matrix[i, j, 20] = 1\n",
        "                box_coordinates = torch.tensor(\n",
        "                    [x_cell, y_cell, width_cell, height_cell]\n",
        "                )\n",
        "                label_matrix[i, j, 21:25] = box_coordinates\n",
        "                label_matrix[i, j, class_label] = 1 \n",
        "        label_matrices.append(label_matrix)                   \n",
        "    return torch.stack(x_b, dim=0), torch.stack(label_matrices, dim=0)  "
      ],
      "metadata": {
        "id": "t2nJBd-J1QDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = VOCDetection(root=\"dataset/\", image_set='train', transform=transforms, download=False)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "bksSXWvHalgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_dataset = VOCDetection(root=\"dataset/\",  image_set='val', transform=transforms, download=False)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "PovUxAJ5crke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Yolo(NUM_CHANNELS, S, B, C + 5*B).to(device)\n",
        "\n",
        "opt = Adam(model.parameters(), lr=2*10-4)\n",
        "loss_fn = YoloLoss()"
      ],
      "metadata": {
        "id": "PP1S7ByTdIvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(train_loader)\n",
        "inputs, labels = next(iterator)\n",
        "inputs.shape, labels.shape"
      ],
      "metadata": {
        "id": "KLO1NT2Oiq1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178688f7-e137-4f46-b781-52a9b9c54e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 3, 333, 500]), torch.Size([16, 7, 7, 30]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from time import sleep\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "        running_loss = 0.\n",
        "        for x_batch, y_batch in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "            y_batch = y_batch.to(device)\n",
        "            x_batch = x_batch.to(device)\n",
        "            opt.zero_grad()\n",
        "            preds = model(x_batch)\n",
        "            loss = loss_fn(preds, y_batch)\n",
        "            \n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            running_loss += loss.item()\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "            sleep(0.1)\n",
        "        print(\"running_loss = {}\".format(running_loss))    "
      ],
      "metadata": {
        "id": "AIyisCHzd59J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}